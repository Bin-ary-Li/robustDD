{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wilds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "from wilds.common.data_loaders import get_eval_loader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import DenseNet\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "batch_size = 256\n",
    "k = 75\n",
    "n_cls = 2\n",
    "label_noise = 0.0\n",
    "max_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/YBZh/Bridging_UDA_SSL\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageDraw\n",
    "\n",
    "\n",
    "def AutoContrast(img, _):\n",
    "    return ImageOps.autocontrast(img)\n",
    "\n",
    "\n",
    "def Brightness(img, v):\n",
    "    assert v >= 0.0\n",
    "    return ImageEnhance.Brightness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Color(img, v):\n",
    "    assert v >= 0.0\n",
    "    return ImageEnhance.Color(img).enhance(v)\n",
    "\n",
    "\n",
    "def Contrast(img, v):\n",
    "    assert v >= 0.0\n",
    "    return ImageEnhance.Contrast(img).enhance(v)\n",
    "\n",
    "\n",
    "def Equalize(img, _):\n",
    "    return ImageOps.equalize(img)\n",
    "\n",
    "\n",
    "def Invert(img, _):\n",
    "    return ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def Identity(img, v):\n",
    "    return img\n",
    "\n",
    "\n",
    "def Posterize(img, v):  # [4, 8]\n",
    "    v = int(v)\n",
    "    v = max(1, v)\n",
    "    return ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Rotate(img, v):  # [-30, 30]\n",
    "    return img.rotate(v)\n",
    "\n",
    "\n",
    "def Sharpness(img, v):  # [0.1,1.9]\n",
    "    assert v >= 0.0\n",
    "    return ImageEnhance.Sharpness(img).enhance(v)\n",
    "\n",
    "\n",
    "def ShearX(img, v):  # [-0.3, 0.3]\n",
    "    return img.transform(img.size, Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
    "\n",
    "\n",
    "def ShearY(img, v):  # [-0.3, 0.3]\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    v = v * img.size[0]\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    v = v * img.size[1]\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
    "\n",
    "\n",
    "def TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
    "\n",
    "\n",
    "def Solarize(img, v):  # [0, 256]\n",
    "    assert 0 <= v <= 256\n",
    "    return ImageOps.solarize(img, v)\n",
    "\n",
    "\n",
    "def Cutout(img, v):  # [0, 60] => percentage: [0, 0.2] => change to [0, 0.5]\n",
    "    assert 0.0 <= v <= 0.5\n",
    "\n",
    "    v = v * img.size[0]\n",
    "    return CutoutAbs(img, v)\n",
    "\n",
    "\n",
    "def CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
    "    if v < 0:\n",
    "        return img\n",
    "    w, h = img.size\n",
    "    x_center = _sample_uniform(0, w)\n",
    "    y_center = _sample_uniform(0, h)\n",
    "\n",
    "    x0 = int(max(0, x_center - v / 2.0))\n",
    "    y0 = int(max(0, y_center - v / 2.0))\n",
    "    x1 = min(w, x0 + v) \n",
    "    y1 = min(h, y0 + v)\n",
    "\n",
    "    xy = (x0, y0, x1, y1)\n",
    "    color = (125, 123, 114)\n",
    "    img = img.copy()\n",
    "    ImageDraw.Draw(img).rectangle(xy, color)\n",
    "    return img\n",
    "\n",
    "\n",
    "FIX_MATCH_AUGMENTATION_POOL = [\n",
    "    (AutoContrast, 0, 1),\n",
    "    (Brightness, 0.05, 0.95),\n",
    "    (Color, 0.05, 0.95),\n",
    "    (Contrast, 0.05, 0.95),\n",
    "    (Equalize, 0, 1),\n",
    "    (Identity, 0, 1),\n",
    "    (Posterize, 4, 8),\n",
    "    (Rotate, -30, 30),\n",
    "    (Sharpness, 0.05, 0.95),\n",
    "    (ShearX, -0.3, 0.3),\n",
    "    (ShearY, -0.3, 0.3),\n",
    "    (Solarize, 0, 256),\n",
    "    (TranslateX, -0.3, 0.3),\n",
    "    (TranslateY, -0.3, 0.3),\n",
    "]\n",
    "\n",
    "\n",
    "def _sample_uniform(a, b):\n",
    "    return torch.empty(1).uniform_(a, b).item()\n",
    "\n",
    "\n",
    "class RandAugment:\n",
    "    def __init__(self, n, augmentation_pool):\n",
    "        assert n >= 1, \"RandAugment N has to be a value greater than or equal to 1.\"\n",
    "        self.n = n\n",
    "        self.augmentation_pool = augmentation_pool\n",
    "\n",
    "    def __call__(self, img):\n",
    "        ops = [\n",
    "            self.augmentation_pool[torch.randint(len(self.augmentation_pool), (1,))]\n",
    "            for _ in range(self.n)\n",
    "        ]\n",
    "        for op, min_val, max_val in ops:\n",
    "            val = min_val + float(max_val - min_val) * _sample_uniform(0, 1)\n",
    "            img = op(img, val)\n",
    "        cutout_val = _sample_uniform(0, 1) * 0.5\n",
    "        img = Cutout(img, cutout_val)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add label noise to train data\n",
    "# metadata = pd.read_csv('noisy_data/camelyon17_v1.0/metadata.csv', \n",
    "#                         index_col=0,\n",
    "#                         dtype={'patient': 'str'})\n",
    "# y_arr = metadata[metadata['split'] == 0]['tumor'].to_numpy() # training split\n",
    "# p = 0.15\n",
    "# flip_loc = np.random.choice([True,False], len(y_arr), p=[p, 1-p])\n",
    "# noisy_y = np.logical_not(y_arr, where = flip_loc, out=y_arr.copy())\n",
    "# metadata.loc[metadata['split']==0, 'tumor'] = noisy_y\n",
    "# metadata.to_csv('noisy_data/camelyon17_v1.0/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the full dataset, and download it if necessary\n",
    "# dataset = get_dataset(dataset=\"camelyon17\", download=True)\n",
    "\n",
    "# Load custom dataset\n",
    "data_dir='noisy_data_0.15'\n",
    "dataset = get_dataset(dataset=\"camelyon17\", download=False, root_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = transforms.Compose(\n",
    "        [RandAugment(2, FIX_MATCH_AUGMENTATION_POOL),\n",
    "        transforms.ToTensor()]\n",
    "    )\n",
    "\n",
    "trans = transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    )\n",
    "\n",
    "train_data = dataset.get_subset(\n",
    "    \"train\",\n",
    "    frac=1,\n",
    "    transform=train_trans,\n",
    ")\n",
    "\n",
    "# Get the test set\n",
    "test_data = dataset.get_subset(\n",
    "    \"test\",\n",
    "    transform=trans\n",
    ")\n",
    "\n",
    "val_data = dataset.get_subset(\n",
    "    'val',\n",
    "    transform=trans\n",
    ")\n",
    "\n",
    "id_val_data = dataset.get_subset(\n",
    "    'id_val',\n",
    "    transform=trans\n",
    ")\n",
    "\n",
    "test_datasets = [test_data, val_data, id_val_data]\n",
    "test_split_names = ['test', 'val', 'idval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitDensenet(pl.LightningModule):\n",
    "    ''' Returns a Densenet121 with growth parameter k. '''\n",
    "    def __init__(self, trainset, testsets, testset_names, \n",
    "                k=32, num_classes=10, lr=1e-4, train_batch_size=256, test_batch_size=256):\n",
    "        super().__init__()\n",
    "        self.trainset = trainset\n",
    "        self.testsets = testsets\n",
    "        self.testset_names = testset_names\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "        self.model = DenseNet(growth_rate=k, num_classes=num_classes)\n",
    "        self.lr = lr\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader=  get_train_loader(\"standard\", self.trainset, \n",
    "                                batch_size=self.train_batch_size,\n",
    "                                num_workers=8, pin_memory=True)\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_loaders = []\n",
    "        for dataset in self.testsets:\n",
    "            loader = get_eval_loader(\"standard\", dataset, \n",
    "                                batch_size=self.test_batch_size,\n",
    "                                num_workers=8, pin_memory=True)\n",
    "            val_loaders.append(loader)\n",
    "        return val_loaders\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels, metadata = batch\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = self.model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "\n",
    "        _, y_pred = torch.max(outputs.data, 1)\n",
    "        return {'loss':loss,\n",
    "                'y_pred':y_pred.cpu(),\n",
    "                'labels':labels.cpu(),\n",
    "                'metadata':metadata.cpu()}\n",
    "    \n",
    "    def training_epoch_end(self, train_step_outputs):\n",
    "        preds = [x[\"y_pred\"] for x in train_step_outputs]\n",
    "        labels = [x[\"labels\"] for x in train_step_outputs]\n",
    "        metadata = [x[\"metadata\"] for x in train_step_outputs]\n",
    "        eval = self.trainset.eval(torch.cat(preds), \n",
    "                            torch.cat(labels), \n",
    "                            torch.cat(metadata))\n",
    "        for key, value in eval[0].items():\n",
    "            if 'avg' in key or 'wg' in key:\n",
    "                self.log(key+'_'+'train', value, on_epoch=True)\n",
    "            else:\n",
    "                self.log(key,value, on_epoch=True)\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx):\n",
    "        inputs, labels, metadata = batch\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = self.model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "\n",
    "        _, y_pred = torch.max(outputs.data, 1)\n",
    "        return {'loss':loss,\n",
    "                'test_idx':dataloader_idx,\n",
    "                'y_pred':y_pred.cpu(),\n",
    "                'labels':labels.cpu(),\n",
    "                'metadata':metadata.cpu()}\n",
    "\n",
    "    def validation_epoch_end(self, val_step_outputs) -> None:\n",
    "        for k in range(len(self.testsets)):\n",
    "            preds = []\n",
    "            labels = []\n",
    "            metadata = []\n",
    "            for x in val_step_outputs[k]:\n",
    "                preds.append(x['y_pred'])\n",
    "                labels.append(x['labels'])\n",
    "                metadata.append(x['metadata'])\n",
    "            eval = self.testsets[k].eval(torch.cat(preds), \n",
    "                                        torch.cat(labels), \n",
    "                                        torch.cat(metadata))\n",
    "            # Logging\n",
    "            testset_name = self.testset_names[k]\n",
    "            for key, value in eval[0].items():\n",
    "                if 'avg' in key or 'wg' in key:\n",
    "                    self.log(key+'_'+testset_name, value)\n",
    "                else:\n",
    "                    self.log(key,value)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitDensenet(train_data, test_datasets, test_split_names, \n",
    "                    k=k, num_classes=n_cls, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl.loggers.CSVLogger('logs', \n",
    "                            name=f\"densenet_width{k}_noise{label_noise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epoch,\n",
    "    accelerator=\"gpu\",\n",
    "    precision=16,\n",
    "    logger=logger,\n",
    "    devices=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | DenseNet | 37.2 M\n",
      "-----------------------------------\n",
      "37.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "37.2 M    Total params\n",
      "74.443    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 6/6 [00:04<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binli/miniconda3/envs/pytorch/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 52, 54, 32, 48, 50, 26, 36, 38, 44, 34, 42])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(np.array([15,26,27,16,24,25,13,18,19,22,17,21]) *2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30,52,58,32,54,50,42,46,48,40,64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89b745ae7b5985586b392e1ddd14281a23a7de24813ea63ee9d4303586a65900"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
